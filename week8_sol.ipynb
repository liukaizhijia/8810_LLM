{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17560e87-5171-41e3-a1a1-406e3ac489c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Self Attention Model\n",
    "\\begin{align}\n",
    "Q &= X W^Q, \\\\\n",
    "K &= X W^K, \\\\\n",
    "V &= X W^V, \\\\\n",
    "\\text{Attention}(Q, K, V) \n",
    "  &= \\operatorname{Softmax}\\!\\left(\\frac{QK^\\top}{\\sqrt{d_k}}\\right)V.\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "\\text{MultiHead}(X) \n",
    "  &= \\text{Concat}\\big(\\text{head}_1, \\ldots, \\text{head}_h\\big) W^O, \\\\\n",
    "\\text{head}_i \n",
    "  &= \\operatorname{Attention}(X W_i^Q, X W_i^K, X W_i^V).\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47eacefb-df00-4907-8f8c-70e2f562f068",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size is: torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class myselfattention(nn.Module):\n",
    "    def __init__(self, d_in, d_out,context_length,bias=True):\n",
    "        super().__init__()\n",
    "        self.W_value=nn.Linear(d_in,d_out,bias=bias)\n",
    "        self.W_query=nn.Linear(d_in,d_out,bias=bias)\n",
    "        self.W_key=nn.Linear(d_in,d_out,bias=bias)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1)) # New\n",
    "    def forward(self, x): \n",
    "        _,num_tokens,_=x.shape\n",
    "        value=self.W_value(x)\n",
    "        query=self.W_query(x)\n",
    "        key=self.W_key(x)\n",
    "        attn_scores=query@key.mT\n",
    "        attn_scores.masked_fill_(self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)      \n",
    "        return nn.Softmax(dim=-1)(attn_scores/key.shape[-1]**0.5)@value\n",
    "myattention=myselfattention(4,4,3)\n",
    "input=torch.rand(2,3,4)\n",
    "output=myattention(input)\n",
    "print(f\"output size is: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c21a2b3-f7e6-459e-b86f-08a893b3ad81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class myselfattention_mh(nn.Module):\n",
    "    def __init__(self, d_in, d_head, d_out,context_length,bias=True):\n",
    "        super().__init__()\n",
    "        self.heads=nn.ModuleList([myselfattention(d_in, d_out//d_head, context_length) for _ in range(d_head)])\n",
    "        self.W_out=nn.Linear(d_out,d_out,bias)\n",
    "    def forward(self, x): \n",
    "        out=torch.cat([self.heads[i](x) for i in range(len(self.heads))], dim=-1)\n",
    "        return self.W_out(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "617281bd-8ece-4c31-a22d-7c421eed1431",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1088"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(myselfattention_mh(16,8,16,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e7889b4-5490-4aab-a67f-e0b331533efc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class mySilu(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x): \n",
    "        return 0.5*x*(1+torch.tanh(torch.sqrt(torch.tensor(2/torch.pi))*(x+0.044715*x**3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f5e2d2a-f000-47c5-bf46-9b437e112b3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ffn(nn.Module):\n",
    "    def __init__(self,dim,dropout=0.1,bias=True):\n",
    "        super().__init__()\n",
    "        self.W1=nn.Linear(dim,4*dim,bias)\n",
    "        self.W2=nn.Linear(4*dim,dim,bias)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        self.silu=mySilu()\n",
    "    def forward(self, x): \n",
    "        return self.dropout(self.W2(self.silu(self.W1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa43e59c-0735-4394-b0ec-a434ea343ee7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class myTransformer(nn.Module):\n",
    "    def __init__(self, heads, dropout, hidden,context_length,bias=True):\n",
    "        super().__init__()\n",
    "        self.myselfattention_mh=myselfattention_mh(hidden,heads,hidden,context_length)#nn.ModuleList([myselfattention(d_in, d_head) for _ in range(d_out//d_head)])\n",
    "        self.layernorm1=nn.LayerNorm(hidden)\n",
    "        self.layernorm2=nn.LayerNorm(hidden)\n",
    "        self.ffn=ffn(hidden,dropout,bias)\n",
    "        self.dropout=dropout\n",
    "    def forward(self, x): \n",
    "        shortcut1=x;\n",
    "        x=self.layernorm1(x)\n",
    "        x=self.myselfattention_mh(x)\n",
    "        x=nn.Dropout(self.dropout)(x)\n",
    "        x=x+shortcut1\n",
    "        shortcut2=x;\n",
    "        x=self.layernorm2(x)\n",
    "        x=self.ffn(x)\n",
    "        x=nn.Dropout(self.dropout)(x)\n",
    "        x=x+shortcut2\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff897df7-3b17-409f-8365-5f05bf6d154c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg={\n",
    "    \"layers\": 12,\n",
    "    \"heads\": 12,\n",
    "    \"dropout\": 0.1,\n",
    "    \"context_length\": 1024,\n",
    "    \"hidden_dim\": 768,\n",
    "    \"voc_size\": 50257\n",
    "}\n",
    "class myGPT2(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers=cfg[\"layers\"]\n",
    "        self.heads=cfg[\"heads\"]\n",
    "        self.dropout=cfg[\"dropout\"]\n",
    "        self.context_length=cfg[\"context_length\"]\n",
    "        self.hidden_dim=cfg[\"hidden_dim\"]\n",
    "        self.voc_size=cfg[\"voc_size\"]\n",
    "        self.wte=nn.Embedding(self.voc_size,self.hidden_dim)\n",
    "        self.wpe=nn.Embedding(self.context_length,self.hidden_dim)\n",
    "        self.layernorm=nn.LayerNorm(self.hidden_dim)\n",
    "        self.linear=nn.Linear(self.hidden_dim,self.voc_size,bias=False)\n",
    "        self.transformerBlocks=nn.ModuleList([myTransformer(self.heads,self.dropout,self.hidden_dim,self.context_length) for _ in range(self.layers)])\n",
    "    def forward(self, x): \n",
    "        batch,length=x.shape\n",
    "        te=self.wte(x);\n",
    "        pe=self.wpe(torch.arange(length, device=x.device));\n",
    "        x=te+pe;\n",
    "        x=nn.Dropout(self.dropout)(x)\n",
    "        x=nn.Sequential(*self.transformerBlocks)(x)\n",
    "        x=self.layernorm(x)\n",
    "        x=self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b4525ab-4f99-4396-95bc-212d096a85e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 50257])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "model=myGPT2(cfg)\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5119c2c1-f8e9-46b3-895e-05ca57187f26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163037184"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7059baf-17fb-40f7-8426-ee3285679cc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_text1=\"I study at Clemson\"\n",
    "input_text2=\"I am a student\"\n",
    "input = [input_text1,input_text2]\n",
    "import tiktoken\n",
    "\n",
    "# Load GPT-2 tokenizer\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "##TODO: how to get the tokens of input\n",
    "tokens = [enc.encode(text) for text in input]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33c6b0fa-6b62-40d4-a12c-f395d209131a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[40, 2050, 379, 27801], [40, 716, 257, 3710]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49debf0e-5215-43f4-b81a-1cccb8323ae0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 50257])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor(tokens)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "067116a2-f62c-4453-8650-d0020168d802",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate(model,tokens,max_length):\n",
    "    for i in range(max_length):\n",
    "        with torch.no_grad():\n",
    "            x=model(tokens)\n",
    "        ##TODO: return the generation with max_length limit\n",
    "        logits=x[:,-1,:]\n",
    "        _,idx=torch.max(logits, dim=-1, keepdim=True)\n",
    "        tokens=torch.cat((tokens, idx), dim=1)\n",
    "    return tokens\n",
    "generated=generate(model,torch.tensor(tokens),6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "712cb47a-bf75-4f3b-ac2d-358ad5c44a0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   40,  2050,   379, 27801, 32070, 16173, 16560, 11995, 46295, 49965],\n",
       "        [   40,   716,   257,  3710, 44535, 13704,  1561, 21770, 45863, 26735]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8bcd6f1-2ecb-409c-b6db-db446fcde032",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 0: I study at Clemson hepat interpreted incorporated Dungeon Chandra GAM\n",
      "Sequence 1: I am a student Visitorsoshi talk Baron deliberations pedestrians\n"
     ]
    }
   ],
   "source": [
    "for i, seq in enumerate(generated.tolist()):\n",
    "    text = enc.decode(seq)\n",
    "    print(f\"Sequence {i}: {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a812abb-467f-4adb-9c2a-7228ca480483",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 716, 257, 3710, 44535, 13704, 1561, 21770, 45863, 26735]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5aa6c7e-52fb-41c8-8551-855149b5d96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kail/.conda/envs/myenv/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2d90117-8097-4b2f-8aa6-702a1625ca45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = \"small.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba03915b-de1d-4b07-b514-1a6bbcab47c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿The Project Gutenberg eBook of Two Centuries of Costume in America, Vol. 1 (1620-1820), by Alice M\n"
     ]
    }
   ],
   "source": [
    "print(text_data[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e64f031-c6c9-4e57-9317-220933d89070",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "help produce our new eBooks, and how to\n",
      "subscribe to our email newsletter to hear about new eBooks.\n"
     ]
    }
   ],
   "source": [
    "print(text_data[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bec55104-2f0d-4ba7-8827-e0d2b15a5d3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 527230\n",
      "Tokens: 140584\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(enc.encode(text_data,disallowed_special=()))\n",
    "\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b9e2096-f894-47ed-9caf-fb9d21fdb2cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from previous_chapters import create_dataloader_v1\n",
    "\n",
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=cfg[\"context_length\"],\n",
    "    stride=cfg[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=cfg[\"context_length\"],\n",
    "    stride=cfg[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0459e9e6-d247-498e-9754-cda080ecee7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    break\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3cc55360-af06-49fb-97e8-e28e913a83e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3856, 1000,  468,  530,   26,  475,  198, 4480,  262, 1049])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9cf8cbbf-7559-468e-be3b-2c69a3106645",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1000,  468,  530,   26,  475,  198, 4480,  262, 1049, 2478])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0,:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e7065b-fcfa-495f-981b-cdbe82e6c7c2",
   "metadata": {},
   "source": [
    "This makes sense as we discussed in class that the output response is just 1 stride increase of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2eee0f9d-b02f-44e5-87e8-e12622e4d3f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 124928\n",
      "Validation tokens: 13312\n",
      "All tokens: 138240\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3c45d5b-1aac-4499-8111-e08d9f7ef9ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch=input_batch.to(device)\n",
    "    target_batch=target_batch.to(device)\n",
    "    prediction=model(input_batch)\n",
    "    return torch.nn.functional.cross_entropy(prediction.flatten(0, 1), target_batch.flatten())\n",
    "    ##TODO: calculate batch loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92c5455a-0304-4532-90fc-b91bc3276f93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device,num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            total_loss += calc_loss_batch(input_batch, target_batch, model, device).item()\n",
    "            ##TODO: calculate total_loss which will call function calc_loss_batch defined above\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8446a95-bd4a-43a0-bd39-fc0c6bffb308",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.991145993842453\n",
      "Validation loss: 10.99047783442906\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device) \n",
    "torch.manual_seed(123) \n",
    "with torch.no_grad(): \n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c30341da-810d-4a5f-9f24-f57b89808d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import generate_text_simple\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.wpe.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aedd8b34-7325-42c4-83eb-9ed2de223ebe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.876, Val loss 9.827\n",
      "Ep 1 (Step 000005): Train loss 8.321, Val loss 8.392\n",
      "Ep 1 (Step 000010): Train loss 7.414, Val loss 7.620\n",
      "Ep 1 (Step 000015): Train loss 7.083, Val loss 7.391\n",
      "Ep 1 (Step 000020): Train loss 7.104, Val loss 7.377\n",
      "Ep 1 (Step 000025): Train loss 6.838, Val loss 7.341\n",
      "Ep 1 (Step 000030): Train loss 6.971, Val loss 7.145\n",
      "Ep 1 (Step 000035): Train loss 6.650, Val loss 7.101\n",
      "Ep 1 (Step 000040): Train loss 6.685, Val loss 6.991\n",
      "Ep 1 (Step 000045): Train loss 6.557, Val loss 6.941\n",
      "Ep 1 (Step 000050): Train loss 6.470, Val loss 6.871\n",
      "Ep 1 (Step 000055): Train loss 6.355, Val loss 6.833\n",
      "Ep 1 (Step 000060): Train loss 6.375, Val loss 6.782\n",
      "Every effort moves you                                                  \n",
      "Ep 2 (Step 000065): Train loss 6.426, Val loss 6.762\n",
      "Ep 2 (Step 000070): Train loss 6.351, Val loss 6.749\n",
      "Ep 2 (Step 000075): Train loss 6.228, Val loss 6.729\n",
      "Ep 2 (Step 000080): Train loss 6.257, Val loss 6.758\n",
      "Ep 2 (Step 000085): Train loss 6.301, Val loss 6.693\n",
      "Ep 2 (Step 000090): Train loss 6.262, Val loss 6.684\n",
      "Ep 2 (Step 000095): Train loss 6.245, Val loss 6.670\n",
      "Ep 2 (Step 000100): Train loss 6.120, Val loss 6.632\n",
      "Ep 2 (Step 000105): Train loss 6.080, Val loss 6.604\n",
      "Ep 2 (Step 000110): Train loss 5.957, Val loss 6.582\n",
      "Ep 2 (Step 000115): Train loss 5.956, Val loss 6.550\n",
      "Ep 2 (Step 000120): Train loss 6.000, Val loss 6.562\n",
      "Every effort moves you                                                  \n",
      "Ep 3 (Step 000125): Train loss 5.932, Val loss 6.531\n",
      "Ep 3 (Step 000130): Train loss 5.845, Val loss 6.526\n",
      "Ep 3 (Step 000135): Train loss 5.879, Val loss 6.512\n",
      "Ep 3 (Step 000140): Train loss 5.902, Val loss 6.547\n",
      "Ep 3 (Step 000145): Train loss 5.874, Val loss 6.488\n",
      "Ep 3 (Step 000150): Train loss 5.672, Val loss 6.499\n",
      "Ep 3 (Step 000155): Train loss 5.809, Val loss 6.477\n",
      "Ep 3 (Step 000160): Train loss 5.602, Val loss 6.448\n",
      "Ep 3 (Step 000165): Train loss 5.751, Val loss 6.448\n",
      "Ep 3 (Step 000170): Train loss 5.735, Val loss 6.423\n",
      "Ep 3 (Step 000175): Train loss 5.697, Val loss 6.400\n",
      "Ep 3 (Step 000180): Train loss 5.624, Val loss 6.376\n",
      "Every effort moves you, and                                 the              \n",
      "Ep 4 (Step 000185): Train loss 5.337, Val loss 6.396\n",
      "Ep 4 (Step 000190): Train loss 5.426, Val loss 6.359\n",
      "Ep 4 (Step 000195): Train loss 5.245, Val loss 6.355\n",
      "Ep 4 (Step 000200): Train loss 5.203, Val loss 6.379\n",
      "Ep 4 (Step 000205): Train loss 5.350, Val loss 6.378\n",
      "Ep 4 (Step 000210): Train loss 5.316, Val loss 6.345\n",
      "Ep 4 (Step 000215): Train loss 5.190, Val loss 6.339\n",
      "Ep 4 (Step 000220): Train loss 4.836, Val loss 6.321\n",
      "Ep 4 (Step 000225): Train loss 5.054, Val loss 6.315\n",
      "Ep 4 (Step 000230): Train loss 5.111, Val loss 6.272\n",
      "Ep 4 (Step 000235): Train loss 5.117, Val loss 6.259\n",
      "Ep 4 (Step 000240): Train loss 5.042, Val loss 6.266\n",
      "Every effort moves you,                                  The, and the The, and  The portrait of the \n",
      "Training completed in 4.02 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = myGPT2(cfg)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 4\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=enc\n",
    ")\n",
    "\n",
    "# Note:\n",
    "# Uncomment the following code to show the execution time\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f029f30-40ba-4e95-893e-3b29f8f05217",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c37434f8-a1d5-4db0-84a5-342b2f701bee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # New (not in book): numerical stability tip to get equivalent results on mps device\n",
    "            # subtract rowwise max before softmax\n",
    "            logits = logits - logits.max(dim=-1, keepdim=True).values\n",
    "            \n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "440166bb-3b14-4e3b-9aff-a9f8c1869176",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you-s, âHman. For some his own\n",
      "And a\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "inference_device = torch.device(\"cpu\")\n",
    "\n",
    "model.to(inference_device)\n",
    "model.eval()\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", enc).to(inference_device),\n",
    "    max_new_tokens=15,\n",
    "    context_size=cfg[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ea2c9e1-2755-43bb-9710-3f291e09faac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 21:33:03.498280: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6cffcb1d-06bc-4f8f-9d28-16ffcf796efa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eeaa11c7-c607-4c2e-9cc6-6758fb47fa5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blocks', 'b', 'g', 'wpe', 'wte']\n"
     ]
    }
   ],
   "source": [
    "print(list(params.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "65fcc4dd-8f32-4ad0-aa2f-b0805e2e3189",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "60c88ebf-108f-43ab-aeb4-520ce60042d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_scratch/slurm.6579593/ipykernel_2325724/1629613674.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.nn.Parameter(torch.tensor(right))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.wpe.weight = assign(gpt.wpe.weight, params['wpe'])\n",
    "    gpt.wte.weight = assign(gpt.wte.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        # print(f\"q_w size is: {q_w.shape}\")\n",
    "        # print(f\"k_w size is: {k_w.shape}\")\n",
    "        # print(f\"v_w size is: {v_w.shape}\")\n",
    "        for h in range(cfg[\"heads\"]):\n",
    "            # print(f\"{gpt.transformerBlocks[b].myselfattention_mh.heads[h].W_query.weight.shape}\")\n",
    "            gpt.transformerBlocks[b].myselfattention_mh.heads[h].W_query.weight = assign(\n",
    "                gpt.transformerBlocks[b].myselfattention_mh.heads[h].W_query.weight, torch.chunk(torch.tensor(q_w.T), cfg[\"heads\"], dim=0)[h])\n",
    "            gpt.transformerBlocks[b].myselfattention_mh.heads[h].W_key.weight = assign(\n",
    "                gpt.transformerBlocks[b].myselfattention_mh.heads[h].W_key.weight, torch.chunk(torch.tensor(k_w.T), cfg[\"heads\"], dim=0)[h])\n",
    "            gpt.transformerBlocks[b].myselfattention_mh.heads[h].W_value.weight = assign(\n",
    "                gpt.transformerBlocks[b].myselfattention_mh.heads[h].W_value.weight, torch.chunk(torch.tensor(v_w.T), cfg[\"heads\"], dim=0)[h])\n",
    "            gpt.transformerBlocks[b].myselfattention_mh.heads[h].W_query.bias = assign(\n",
    "                gpt.transformerBlocks[b].myselfattention_mh.heads[h].W_query.bias, torch.chunk(torch.tensor(q_b), cfg[\"heads\"], dim=0)[h])\n",
    "            gpt.transformerBlocks[b].myselfattention_mh.heads[h].W_key.bias = assign(\n",
    "                gpt.transformerBlocks[b].myselfattention_mh.heads[h].W_key.bias, torch.chunk(torch.tensor(k_b), cfg[\"heads\"], dim=0)[h])\n",
    "            gpt.transformerBlocks[b].myselfattention_mh.heads[h].W_value.bias = assign(\n",
    "                gpt.transformerBlocks[b].myselfattention_mh.heads[h].W_value.bias, torch.chunk(torch.tensor(v_b), cfg[\"heads\"], dim=0)[h])\n",
    "            \n",
    "        \n",
    "        #print(f\"q_b size is: {q_b.shape}\")\n",
    "        \n",
    "\n",
    "        gpt.transformerBlocks[b].myselfattention_mh.W_out.weight = assign(\n",
    "            gpt.transformerBlocks[b].myselfattention_mh.W_out.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.transformerBlocks[b].myselfattention_mh.W_out.bias = assign(\n",
    "            gpt.transformerBlocks[b].myselfattention_mh.W_out.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.transformerBlocks[b].ffn.W1.weight = assign(\n",
    "            gpt.transformerBlocks[b].ffn.W1.weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.transformerBlocks[b].ffn.W1.bias = assign(\n",
    "            gpt.transformerBlocks[b].ffn.W1.bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        # gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "        #     gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "        #     params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.transformerBlocks[b].ffn.W2.weight = assign(\n",
    "            gpt.transformerBlocks[b].ffn.W2.weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.transformerBlocks[b].ffn.W2.bias = assign(\n",
    "            gpt.transformerBlocks[b].ffn.W2.bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "        # gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "        #     gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "        #     params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.transformerBlocks[b].layernorm1.weight = assign(\n",
    "            gpt.transformerBlocks[b].layernorm1.weight, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.transformerBlocks[b].layernorm1.bias = assign(\n",
    "            gpt.transformerBlocks[b].layernorm1.bias, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.transformerBlocks[b].layernorm2.weight = assign(\n",
    "            gpt.transformerBlocks[b].layernorm1.weight, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.transformerBlocks[b].layernorm2.bias = assign(\n",
    "            gpt.transformerBlocks[b].layernorm1.bias, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.layernorm.weight = assign(gpt.layernorm.weight, params[\"g\"])\n",
    "    gpt.layernorm.bias = assign(gpt.layernorm.bias, params[\"b\"])\n",
    "    gpt.linear.weight = assign(gpt.linear.weight, params[\"wte\"])\n",
    "    \n",
    "    \n",
    "load_weights_into_gpt(model, params)\n",
    "model.to(device);\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "054abe40-dda0-42c3-b201-c24aafeee5b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you towards yourself. As an adult, one of your first jobs must be in some way of life: to survive and care for\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(12345)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", enc).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=cfg[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8584cb01-4bc9-47df-bf7b-dddd160f6956",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
